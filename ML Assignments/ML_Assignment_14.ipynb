{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4190f28",
   "metadata": {},
   "source": [
    "#### 1. What is the concept of supervised learning? What is the significance of the name?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbca6b7",
   "metadata": {},
   "source": [
    "#### Ans:\n",
    "Supervised learning is a sub-category of machine learning in which we use a dataset that has a supervising variable to create machine learning modls that is used for making predictions. It is given the name supervised because of the use of supervising variable which helps in supervising the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8593f098",
   "metadata": {},
   "source": [
    "#### 2. In the hospital sector, offer an example of supervised learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3141910e",
   "metadata": {},
   "source": [
    "#### Ans:\n",
    "In hospital sector, machine learning models are made to predict whether a person has a particular disease or not based on their body features and symptoms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533c85b1",
   "metadata": {},
   "source": [
    "#### 3. Give three supervised learning examples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2698c9",
   "metadata": {},
   "source": [
    "#### Ans:\n",
    "1. Prediction of prices of flights.\n",
    "2. Classification of emails as either spam or non-spam.\n",
    "3. Classification of images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced181de",
   "metadata": {},
   "source": [
    "#### 4. In supervised learning, what are classification and regression?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c3c1ba",
   "metadata": {},
   "source": [
    "#### Ans:\n",
    "Classification is a supervised machine learning technique in which the prediction made belongs to a categorical variable with finite an discrete set of values.\n",
    "\n",
    "Regression is a supervised machine learning technique in which the prediction made belongs to a numerical variable with continuous set of values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25ebc64",
   "metadata": {},
   "source": [
    "#### 5. Give some popular classification algorithms as examples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f889b658",
   "metadata": {},
   "source": [
    "#### Ans:\n",
    "Some popular classififcation algorithms are:\n",
    "1. Logistic regression\n",
    "2. Support vector classiier\n",
    "3. Decision Tree\n",
    "4. Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd931fa9",
   "metadata": {},
   "source": [
    "#### 6. Briefly describe the SVM model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7926319",
   "metadata": {},
   "source": [
    "#### Ans:\n",
    "Support Vector Machine or SVM is one of the most popular Supervised Learning algorithms, which is used for Classification as well as Regression problems. However, primarily, it is used for Classification problems in Machine Learning. The goal of the SVM algorithm is to create the best line or decision boundary that can segregate n-dimensional space into classes so that we can easily put the new data point in the correct category in the future. This best decision boundary is called a hyperplane. SVM chooses the extreme points/vectors that help in creating the hyperplane. These extreme cases are called as support vectors, and hence algorithm is termed as Support Vector Machine. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eedb3c",
   "metadata": {},
   "source": [
    "#### 7. In SVM, what is the cost of misclassification?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b80fd5",
   "metadata": {},
   "source": [
    "#### Ans:\n",
    "In the SVM algorithm, we are looking to maximize the margin between the data points and the hyperplane. The loss function that helps maximize the margin is hinge loss. The cost is 0 if the predicted value and the actual value are of the same sign. If they are not, we then calculate the loss value. We also add a regularization parameter the cost function. The objective of the regularization parameter is to balance the margin maximization and loss. When there is no misclassification, i.e our model correctly predicts the class of our data point, we only have to update the gradient from the regularization parameter. When there is a misclassification, i.e our model make a mistake on the prediction of the class of our data point, we include the loss along with the regularization parameter to perform gradient update."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc6ecbb",
   "metadata": {},
   "source": [
    "#### 8. In the SVM model, define Support Vectors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019c584a",
   "metadata": {},
   "source": [
    "#### Ans:\n",
    "The data points or vectors that are the closest to the hyperplane and which affect the position of the hyperplane are termed as Support Vector. Since these vectors support the hyperplane, hence called a Support vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09567585",
   "metadata": {},
   "source": [
    "#### 9. In the SVM model, define the kernel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb05c19",
   "metadata": {},
   "source": [
    "#### Ans:\n",
    "The SVM kernel is a function that takes low dimensional input space and transforms it into higher-dimensional space, ie it converts non separable problem to separable problem. It is mostly useful in non-linear separation problems. Simply put the kernel, it does some extremely complex data transformations then finds out the process to separate the data based on the labels or outputs defined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53418587",
   "metadata": {},
   "source": [
    "#### 10. What are the factors that influence SVM's effectiveness?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c8fe27",
   "metadata": {},
   "source": [
    "#### Ans:\n",
    "1. Large number of training point.\n",
    "2. Kernel used. We have various options available with kernel like, “linear”, “rbf”,”poly” and others (default value is “rbf”).  Here “rbf” and “poly” are useful for non-linear hyper-plane.\n",
    "3. Gamma parameter. Higher the value of gamma, will try to exact fit the as per training data set i.e. generalization error and cause over-fitting problem.\n",
    "4. Penalty parameter C of the error term. It also controls the trade-off between smooth decision boundaries and classifying the training points correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81992b53",
   "metadata": {},
   "source": [
    "#### 11. What are the benefits of using the SVM model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b90a8f",
   "metadata": {},
   "source": [
    "#### Ans:\n",
    "1. Effective in high dimensional cases\n",
    "2. Its memory efficient as it uses a subset of training points in the decision function called support vectors\n",
    "3. Different kernel functions can be specified for the decision functions and its possible to specify custom kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6c1d7f",
   "metadata": {},
   "source": [
    "#### 12.  What are the drawbacks of using the SVM model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcda42cf",
   "metadata": {},
   "source": [
    "#### Ans:\n",
    "1. It doesn’t perform well when we have large data set because the required training time is higher\n",
    "2. It also doesn’t perform very well, when the data set has more noise i.e. target classes are overlapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86858999",
   "metadata": {},
   "source": [
    "#### 13. Notes should be written on\n",
    "\n",
    "1. The kNN algorithm has a validation flaw.\n",
    "\n",
    "2. In the kNN algorithm, the k value is chosen.\n",
    "\n",
    "3. A decision tree with inductive bias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cccf244",
   "metadata": {},
   "source": [
    "#### Ans:\n",
    "1. The kNN algorithm has a validation flaw: The knn algorithm has validation flaw because there is only hypertuning parameter K, and no learning parameter. The point of cross-validation is to get the best learning parameter only.\n",
    "\n",
    "2. In the kNN algorithm, the k value is chosen: The value of k is chosen manually by testing different values of k on the test set, and whichever value of k gives the best accuracy that k is used.\n",
    "\n",
    "3. A decision tree with inductive bias: Before learning a model given a data and a learning algorithm, there are a few assumptions a learner makes about the algorithm. These assumptions are called the inductive bias. It is like the property of the algorithm. For eg. in the case of decision trees, the depth of the tress is the inductive bias. If the depth of the tree is too low, then there is too much generalisation in the model. Similarly, if the depth of the tree is too much, there is too less generalisation and while testing the model on a new example. Shorter trees are preferred over longer ones. Trees that place high information gain attributes close to the root are preferred over those that do not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f5e591",
   "metadata": {},
   "source": [
    "#### 14. What are some of the benefits of the kNN algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c11460",
   "metadata": {},
   "source": [
    "#### Ans:\n",
    "1. It is simple to implement.\n",
    "2. It is robust to the noisy training data\n",
    "3. It can be more effective if the training data is large.\n",
    "4. There’s no need to build a model, tune several parameters, or make additional assumptions.\n",
    "5. The algorithm is versatile. It can be used for classification, regression, and search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713c1dac",
   "metadata": {},
   "source": [
    "#### 15. What are some of the kNN algorithm's drawbacks?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8326d6e2",
   "metadata": {},
   "source": [
    "#### Ans:\n",
    "1. Always needs to determine the value of K which may be complex some time.\n",
    "2. The computation cost is high because of calculating the distance between the data points for all the training samples.\n",
    "3. The algorithm gets significantly slower as the number of training samples and/or predictors variables increase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a261f7",
   "metadata": {},
   "source": [
    "#### 16. Explain the decision tree algorithm in a few words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305c4e7b",
   "metadata": {},
   "source": [
    "#### Ans:\n",
    "Decision tree algorithm falls under the category of supervised learning. They can be used to solve both regression and classification problems. Decision tree uses the tree representation to solve the problem in which each leaf node corresponds to a class label and attributes are represented on the internal node of the tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7034363",
   "metadata": {},
   "source": [
    "#### 17. What is the difference between a node and a leaf in a decision tree?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b42f20",
   "metadata": {},
   "source": [
    "#### Ans:\n",
    "Nodes are used to make any decision and have multiple branches, whereas Leaf nodes are the output of those decisions and do not contain any further branches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d012b3d",
   "metadata": {},
   "source": [
    "#### 18. What is a decision tree's entropy?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e12f26",
   "metadata": {},
   "source": [
    "#### Ans:\n",
    "Entropy is a measure of disorder or impurity in the given dataset. In the decision tree, messy data are split based on values of the feature vector associated with each data point. With each split, the data becomes more homogenous which will decrease the entropy. However, some data in some nodes will not be homogenous, where the entropy value will not be small. The higher the entropy, the harder it is to draw any conclusion. When the tree finally reaches the terminal or leaf node maximum purity is added."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f13ff1",
   "metadata": {},
   "source": [
    "#### 19. In a decision tree, define knowledge gain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1520c5b1",
   "metadata": {},
   "source": [
    "#### Ans:\n",
    "Entropy measures impurity in the data and information gain measures reduction in impurity in the data. The feature which has minimum impurity will be considered as the root node. Information gain is used to decide which feature to split on at each step in building the tree. The creation of sub-nodes increases the homogeneity, that is decreases the entropy of these nodes. The more the child node is homogeneous, the more the variance will be decreased after each split. Thus Information Gain is the variance reduction and can calculate by how much the variance decreases after each split. Information gain of a parent node can be calculated as the entropy of the parent node subtracted entropy of the weighted average of the child node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50280e14",
   "metadata": {},
   "source": [
    "#### 20. Choose three advantages of the decision tree approach and write them down.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089c18c6",
   "metadata": {},
   "source": [
    "#### Ans:\n",
    "1. It is simple to understand as it follows the same process which a human follow while making any decision in real-life.\n",
    "2. It can be very useful for solving decision-related problems.\n",
    "3. It helps to think about all the possible outcomes for a problem.\n",
    "4. There is less requirement of data cleaning compared to other algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76fe0aa",
   "metadata": {},
   "source": [
    "#### 21. Make a list of three flaws in the decision tree process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dec6a98",
   "metadata": {},
   "source": [
    "#### Ans:\n",
    "1. The decision tree contains lots of layers, which makes it complex.\n",
    "2. It may have an overfitting issue, which can be resolved using the Random Forest algorithm.\n",
    "3. For more class labels, the computational complexity of the decision tree may increase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81db773c",
   "metadata": {},
   "source": [
    "#### 22. Briefly describe the random forest model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2881aac5",
   "metadata": {},
   "source": [
    "#### Ans:\n",
    "Random Forest is a popular machine learning algorithm that belongs to the supervised learning technique. It can be used for both Classification and Regression problems in ML. It is based on the concept of ensemble learning, which is a process of combining multiple classifiers to solve a complex problem and to improve the performance of the model. As the name suggests, \"Random Forest is a classifier that contains a number of decision trees on various subsets of the given dataset and takes the average to improve the predictive accuracy of that dataset.\" Instead of relying on one decision tree, the random forest takes the prediction from each tree and based on the majority votes of predictions, and it predicts the final output. The greater number of trees in the forest leads to higher accuracy and prevents the problem of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1082fca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
